## Обработка и генерация изображений

# Домашняя работа № 3
Калиновский Константин Сергеевич

Задача множественной классификации

Датасет CIFAR-10

В качестве бейзлайна выбрана простая модель со слоями конволюции и dense слоем на выходе

Метрики базовой модели:
![image](https://github.com/oldrzym/ig/assets/115554194/1c3c292a-cd36-425b-adf0-4371438d37d7)

# Эксперимент 1

Из графиков видно, что экспериментальная модель демонстрирует быстрое улучшение производительности на тренировочных данных, однако показывает признаки переобучения при проверке на валидационных данных: после определенного момента увеличиваются потери и стабилизируются показатели точности и полноты. В бейзлайн модели метрики улучшаются более равномерно, что свидетельствует о лучшей обобщающей способности. Это может означать, что экспериментальной модели необходимы дополнительные методы борьбы с переобучением, такие как более сильная регуляризация или расширение набора валидационных данных.
![image](https://github.com/oldrzym/ig/assets/115554194/2861e89e-6c93-4c42-8d1b-d5c3a27d2ea6)
![image](https://github.com/oldrzym/ig/assets/115554194/b8ad44fb-6cfe-4c83-9968-a542051d28ad)

# Эксперимент 2

1. **Динамика обучения**:
   - Во втором эксперименте наблюдается устойчивое снижение функции потерь как на тренировочных, так и на валидационных данных, что указывает на эффективность обучения модели.
   - Точность и полнота на валидационных данных растут, но медленнее, чем на тренировочных, что может свидетельствовать о некотором переобучении, хотя разрыв не такой значительный, как мог бы быть при серьёзном переобучении.

2. **Метрики классификации)**:
   - Второй эксперимент показывает улучшение точности и полноты по сравнению с первым экспериментом для некоторых классов, что может указывать на улучшенную способность модели различать определенные категории.
   - Общая точность во втором эксперименте (0.73) не изменилась по сравнению с первым экспериментом (также 0.73), однако наблюдается незначительное улучшение полноты и F1-меры.

В целом, второй эксперимент с 50% датасета показывает схожую общую эффективность с первым экспериментом, однако отдельные классы классифицируются лучше. Это может говорить о том, что использование половины датасета не привело к значительному ухудшению качества модели, что полезно в случаях, когда имеются ограничения по объему данных или вычислительным ресурсам. На основе этих данных можно сделать вывод о том, что модель справляется с задачей классификации достаточно хорошо, но возможно потребуется дальнейшая настройка и оптимизация для уменьшения переобучения и улучшения результатов для отдельных классов.
![image](https://github.com/oldrzym/ig/assets/115554194/e79654b6-6c10-4074-963a-bc1ae6eb7aad)
![image](https://github.com/oldrzym/ig/assets/115554194/925d3518-1d58-4846-a711-35b7cfba9fe7)

# Эксперимент 3

Можно сделать следующие выводы относительно третьего эксперимента:

1. **Динамика обучения**:
   - По сравнению с предыдущими экспериментами, функция потерь на тренировочных данных уменьшается стабильно, но валидационные потери показывают меньшее снижение и более раннее выравнивание, что может указывать на переобучение или на недостаточное количество данных для обучения.
   - Точность на тренировочных данных увеличивается постепенно, но валидационная точность растет медленнее и достигает меньшего значения, что подтверждает предположение о переобучении.
   - Динамика полноты (recall) аналогична динамике точности, что снова подчеркивает возможность переобучения.

2. **Метрики классификации**:
   - Общая точность и полнота в третьем эксперименте ниже, чем в предыдущих экспериментах и бейзлайне, что указывает на ухудшение способности модели обобщать информацию на новых данных.
   - Результаты по классам также демонстрируют более низкие значения F1-меры, что может быть следствием уменьшения тренировочного набора данных до 10% от исходного объема.

В целом, результаты третьего эксперимента показывают, что значительное уменьшение объема тренировочных данных приводит к ухудшению качества модели. Это может быть вызвано недостаточным количеством примеров для обучения, что не позволяет модели адекватно научиться распознавать разнообразные особенности в данных. Эти результаты подчеркивают важность достаточного объема данных для обучения глубоких нейронных сетей.

![image](https://github.com/oldrzym/ig/assets/115554194/c16a7bf0-da48-45af-b3f7-b4c9f1d85fbe)
![image](https://github.com/oldrzym/ig/assets/115554194/0a55bb14-1bb2-4228-a6cc-727b790ead21)

# Выводы по результатам экспериментов
На основе предоставленных графиков динамики обучения и валидации моделей, а также результатов трёх экспериментов можно сделать следующие выводы:

1. **Функция потерь (Loss)**:
   - Во всех трёх экспериментах наблюдается снижение тренировочных потерь, что указывает на эффективность обучения модели в каждом случае.
   - Валидационные потери также снижаются, однако в экспериментах 2 и 3 они начинают выравниваться раньше по сравнению с экспериментом 1, что может свидетельствовать о недостаточном количестве данных для обучения или о начале переобучения.

2. **Точность (Accuracy)**:
   - Улучшение тренировочной точности наблюдается во всех экспериментах, но в эксперименте 3 рост точности замедляется, что может быть следствием обучения на сокращенном датасете.
   - Валидационная точность в эксперименте 1 выше, чем в экспериментах 2 и 3, что подчеркивает важность размера тренировочного набора данных для обобщающей способности модели.

3. **Точность (Precision) и Полнота (Recall)**:
   - Наблюдается аналогичная динамика улучшения тренировочных метрик Precision и Recall во всех трёх экспериментах.
   - Валидационные метрики Precision и Recall также улучшаются, но в экспериментах 2 и 3 заметно, что кривые выравниваются быстрее и достигают ниже максимального значения, что может указывать на переобучение модели в условиях ограниченного набора данных.

Обобщая результаты всех трёх экспериментов, можно сказать, что уменьшение объема тренировочного датасета приводит к снижению точности и полноты на валидационном наборе данных, а также к более раннему выравниванию валидационных потерь. Это подчеркивает важность достаточного количества данных для обучения, чтобы обеспечить хорошую обобщающую способность модели. При этом стоит отметить, что даже при существенном уменьшении объема данных модели всё ещё способны учиться и достигать приемлемой производительности, что может быть полезно в условиях, когда доступ к большому количеству данных ограничен.
![image](https://github.com/oldrzym/ig/assets/115554194/3fecd88c-9c25-42d8-98ed-8f38a27eba69)
![image](https://github.com/oldrzym/ig/assets/115554194/10d82c73-4fe1-4d56-a22f-02842525bcfa)
![image](https://github.com/oldrzym/ig/assets/115554194/ed61d2fa-3e86-4469-ad9b-a914d77c8358)
![image](https://github.com/oldrzym/ig/assets/115554194/52671882-e312-4eb5-ae02-25e8de12def7)

